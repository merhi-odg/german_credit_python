{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Notebook to ModelOp Center:\n",
    "## Training, Evaluating, and Conforming a Model for Deployment\n",
    "\n",
    "\n",
    "In this notebook, we demonstrate the process of \n",
    "1. training a model, \n",
    "2. evaluating its performace, \n",
    "3. saving it for later use,\n",
    "4. and conforming it to MOC standards.\n",
    "\n",
    "More specifically, we will train a logistic regression classifier on the German Credit Data dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I - Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by loading relevant libraries. We will need `sklearn` for model training, and `aequitas` for bias detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.group import Group\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, \\\n",
    "                            f1_score, fbeta_score, confusion_matrix\n",
    "\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **German Credit Data** dataset can be found here: https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data). Download it and load it from a *CSV* file. For our purposes, the dataset has been modified slightly to include an `id` column, and a `gender` column (engineered from `status_sex`, used to demonstarte bias). The target variable is under `label`. We have mapped the labels `[1,2]` to `[0,1]`, where `1` indicates the positive class (loan default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"german_credit_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['id', 'duration_months', 'credit_amount', 'installment_rate',\n",
       "       'present_residence_since', 'age_years', 'number_existing_credits',\n",
       "       'checking_status', 'credit_history', 'purpose', 'savings_account',\n",
       "       'present_employment_since', 'debtors_guarantors', 'property',\n",
       "       'installment_plans', 'housing', 'job', 'number_people_liable',\n",
       "       'telephone', 'foreign_worker', 'gender', 'label'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>duration_months</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>present_residence_since</th>\n",
       "      <th>age_years</th>\n",
       "      <th>number_existing_credits</th>\n",
       "      <th>checking_status</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>debtors_guarantors</th>\n",
       "      <th>property</th>\n",
       "      <th>installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>job</th>\n",
       "      <th>number_people_liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>2</td>\n",
       "      <td>A11</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>...</td>\n",
       "      <td>A101</td>\n",
       "      <td>A121</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5951</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>A12</td>\n",
       "      <td>A32</td>\n",
       "      <td>A43</td>\n",
       "      <td>...</td>\n",
       "      <td>A101</td>\n",
       "      <td>A121</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2096</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>A14</td>\n",
       "      <td>A34</td>\n",
       "      <td>A46</td>\n",
       "      <td>...</td>\n",
       "      <td>A101</td>\n",
       "      <td>A121</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>A172</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>7882</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>A11</td>\n",
       "      <td>A32</td>\n",
       "      <td>A42</td>\n",
       "      <td>...</td>\n",
       "      <td>A103</td>\n",
       "      <td>A122</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>4870</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>A11</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>...</td>\n",
       "      <td>A101</td>\n",
       "      <td>A124</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>A173</td>\n",
       "      <td>2</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  duration_months  credit_amount  installment_rate  \\\n",
       "0   0                6           1169                 4   \n",
       "1   1               48           5951                 2   \n",
       "2   2               12           2096                 2   \n",
       "3   3               42           7882                 2   \n",
       "4   4               24           4870                 3   \n",
       "\n",
       "   present_residence_since  age_years  number_existing_credits  \\\n",
       "0                        4         67                        2   \n",
       "1                        2         22                        1   \n",
       "2                        3         49                        1   \n",
       "3                        4         45                        1   \n",
       "4                        4         53                        2   \n",
       "\n",
       "  checking_status credit_history purpose  ... debtors_guarantors property  \\\n",
       "0             A11            A34     A43  ...               A101     A121   \n",
       "1             A12            A32     A43  ...               A101     A121   \n",
       "2             A14            A34     A46  ...               A101     A121   \n",
       "3             A11            A32     A42  ...               A103     A122   \n",
       "4             A11            A33     A40  ...               A101     A124   \n",
       "\n",
       "  installment_plans housing   job number_people_liable telephone  \\\n",
       "0              A143    A152  A173                    1      A192   \n",
       "1              A143    A152  A173                    1      A191   \n",
       "2              A143    A152  A172                    2      A191   \n",
       "3              A143    A153  A173                    2      A191   \n",
       "4              A143    A153  A173                    2      A191   \n",
       "\n",
       "   foreign_worker  gender label  \n",
       "0            A201    male     0  \n",
       "1            A201  female     1  \n",
       "2            A201    male     0  \n",
       "3            A201    male     0  \n",
       "4            A201    male     1  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all numeric columns need to be considered as numeric features. For example, `number_people_liable` only has two unique discrete values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    845\n",
       "2    155\n",
       "Name: number_people_liable, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.number_people_liable.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may therefore treat it as a categorical feature. Note, however, that we may need to reconsider this option if more values appear in testing phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.number_people_liable = data.number_people_liable.astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before proceeding any further with model development, let us split the original dataset into two sets: a **baseline** set that will be used as a reference set, and a **sample** set which will mimic input data to the model once the model is in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline, df_sample = train_test_split(data, train_size=0.8, random_state=0)\n",
    "\n",
    "df_baseline.to_json('df_baseline.json', orient='records', lines=True)\n",
    "df_sample.to_json('df_sample.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train a **Logistic Regression** classifier. Since our data contains categorical features, we will need to start our pipeline with an encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    OneHotEncoder(\n",
    "        handle_unknown='ignore', \n",
    "        sparse=True\n",
    "    ),\n",
    "    LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression** has multiple parameters which can be tuned. Among these are `C`, `solver`, and `class_weight`, which will be optimised by **GridSearchCV**. We provide GridSearchCV a list of values for each of these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    logisticregression__C=np.logspace(-4, 4, 50), # Inverse of regularization strength\n",
    "    logisticregression__solver=['liblinear', 'lbfgs', 'newton-cg'],\n",
    "    logisticregression__class_weight=['balanced', None]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data still contains non-predictive features, such as `id`, `label` and `gender` (excluded to remove explicit bias). We remove these below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_features = [\n",
    "    f for f in list(data.columns.values) \n",
    "    if f not in ['id', 'label', 'gender']\n",
    "]\n",
    "\n",
    "# we'll also pickle this predictive features list for later use\n",
    "pickle.dump(predictive_features, open('predictive_features.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a sanity check, let us see which features are automatically encoded as **numeric**, and which are encoded as **categorical**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    f for f in list(data.select_dtypes(include=['category', 'object'])) \n",
    "    if f in predictive_features\n",
    "]\n",
    "\n",
    "numeric_features = [\n",
    "    f for f in predictive_features \n",
    "    if f not in categorical_features\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical features**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checking_status', 'credit_history', 'purpose', 'savings_account', 'present_employment_since', 'debtors_guarantors', 'property', 'installment_plans', 'housing', 'job', 'number_people_liable', 'telephone', 'foreign_worker']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numeric features**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['duration_months', 'credit_amount', 'installment_rate', 'present_residence_since', 'age_years', 'number_existing_credits']\n"
     ]
    }
   ],
   "source": [
    "print(numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything looks good; let us proceed with training. We need to specify **predictive** and **response** variables for each of the training and test sets. We set these by filtering the baseline and sample sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_baseline[predictive_features]\n",
    "X_test = df_sample[predictive_features]\n",
    "\n",
    "y_train = df_baseline['label']\n",
    "y_test = df_sample['label']\n",
    "\n",
    "X_train.to_json('X_train.json', orient='records', lines=True)\n",
    "X_test.to_json('X_test.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now fit the classifier to the training data. Since \"it is worse to classify a customer as good when they are bad, than it is to classify a customer as bad when they are good\", we will use an **F_beta metric**, with `beta=2`, to judge the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS = GridSearchCV(\n",
    "    estimator=pipeline, \n",
    "    param_grid=parameters,\n",
    "    n_jobs=-1,\n",
    "    scoring=make_scorer(fbeta_score, beta=2),\n",
    "    cv=RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n",
    ")\n",
    "clf_GS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the parameters of the best estimator more carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that the best logistic regression classifier is one with a `solver='lbfgs'` and `class_weight='balanced'`. This classifier achived the best score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II - Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before saving our trained model for further use, let's look at some performance metrics. We will evaluate the model on both the training and test sets; we would like to see a stable performance.\n",
    "\n",
    "For repeatability, let's define a function which computes multiple metrics at-a-time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y, y_preds):\n",
    "    \"\"\"\n",
    "    A function to evaluate a classification model\n",
    "    \n",
    "    param: y: true (actual) labels\n",
    "    param: y_preds: predicted labels (as scored by model)\n",
    "    \n",
    "    return: mutiple classification performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    return [\n",
    "        accuracy_score(y, y_preds),\n",
    "        precision_score(y, y_preds),\n",
    "        recall_score(y, y_preds),\n",
    "        f1_score(y, y_preds),\n",
    "        fbeta_score(y, y_preds, beta=2),\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now compute predictions on both training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = clf_GS.best_estimator_.predict(X_test)\n",
    "y_train_preds = clf_GS.best_estimator_.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will display performance metrics in a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preformance_df = pd.DataFrame(\n",
    "    data=[{}],\n",
    "    columns=['Accuracy', 'Precision', 'Recall', 'F1 score', 'F2 Score'],\n",
    "    index=['Training Set', 'Test Set']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preformance_df.loc['Training Set',:] = compute_metrics(y=y_train, y_preds=y_train_preds)\n",
    "preformance_df.loc['Test Set',:] = compute_metrics(y=y_test, y_preds=y_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preformance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it's good to see that the performance on the training set is not too far off from the performance on the test set, further model improvements are needed to achieve better F2 scores. For now, we will contend with this model and use it to produce new predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III - Saving and Loading the Trained Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the model is **trained** and **evaluated**, we save it in a binary format. It will then be loaded and used to make new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf_GS.best_estimator_, open(\"logreg_classifier.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is reloaded on-demand as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_classifier = pickle.load(open(\"logreg_classifier.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions are produced on-demand by calling the `predict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = logreg_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IV - Evaluating Bias on Protected Classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `gender` is a protected class, we have excluded from the list of predictive features. However, this does not guarantee that the model is not implicitely biased, as `gender` could potentially be inferred from other features. It is therefore imperative that we evaluate our model for Bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To that end, let us produce some predictions and append them to our labeled baseline and sample sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored = df_baseline.copy(deep=True)\n",
    "df_baseline_scored[\"score\"] = logreg_classifier.predict(\n",
    "    df_baseline[predictive_features])\n",
    "\n",
    "df_sample_scored = df_sample.copy(deep=True)\n",
    "df_sample_scored[\"score\"] = logreg_classifier.predict(\n",
    "    df_sample[predictive_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aequitas library requires the true label to be encoded as 'label_value', so let us rename that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored.rename(columns={'label': 'label_value'}, inplace=True)\n",
    "df_sample_scored.rename(columns={'label': 'label_value'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save these two DataFrames before proceeding further:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored.to_json('df_baseline_scored.json', orient='records', lines=True)\n",
    "df_sample_scored.to_json('df_sample_scored.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we call the aequitas preprocessing function on our datasets, filtered to the features we care about: `score` (prediction), `label_value` (true label), and `gender` (protected class):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored_processed, _ = preprocess_input_df(\n",
    "    df_baseline_scored.loc[:,['score', 'label_value', 'gender']]\n",
    ")\n",
    "df_sample_scored_processed, _ = preprocess_input_df(\n",
    "    df_sample_scored.loc[:,['score', 'label_value', 'gender']]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by computing some `Group` Metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_baseline, g_sample = Group(), Group()\n",
    "xtab_baseline, _ = g_baseline.get_crosstabs(df_baseline_scored_processed)\n",
    "xtab_sample, _ = g_sample.get_crosstabs(df_sample_scored_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_metrics_baseline = g_baseline.list_absolute_metrics(xtab_baseline)\n",
    "absolute_metrics_sample = g_sample.list_absolute_metrics(xtab_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the absolute metrics, computed on baseline and sample sets, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab_baseline[['attribute_name', 'attribute_value'] + absolute_metrics_baseline].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab_sample[['attribute_name', 'attribute_value'] + absolute_metrics_sample].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add some raw counts (group sizes) as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab_baseline[[col for col in xtab_baseline.columns if col not in absolute_metrics_baseline]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab_sample[[col for col in xtab_sample.columns if col not in absolute_metrics_sample]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it for `Group` metrics. Let's move on to `Bias` metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b_baseline, b_sample = Bias(), Bias()\n",
    "\n",
    "bdf_baseline = b_baseline.get_disparity_predefined_groups(\n",
    "    xtab_baseline, \n",
    "    original_df=df_baseline_scored_processed, \n",
    "    ref_groups_dict={'gender':'male'}, alpha=0.05, mask_significance=True\n",
    ")\n",
    "\n",
    "bdf_sample = b_sample.get_disparity_predefined_groups(\n",
    "    xtab_sample, \n",
    "    original_df=df_sample_scored_processed, \n",
    "    ref_groups_dict={'gender':'male'}, alpha=0.05, mask_significance=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute **disparity** metrics as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_disparities_baseline = b_baseline.list_disparities(bdf_baseline)\n",
    "calculated_disparities_sample = b_sample.list_disparities(bdf_sample)\n",
    "\n",
    "disparity_metrics_df_baseline = bdf_baseline[\n",
    "    ['attribute_name', 'attribute_value'] + \\\n",
    "        calculated_disparities_baseline\n",
    "    ]\n",
    "disparity_metrics_df_sample = bdf_sample[\n",
    "    ['attribute_name', 'attribute_value'] + \\\n",
    "        calculated_disparities_sample\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the computed disparity metrics on baseline and sample sets, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disparity_metrics_df_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disparity_metrics_df_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the disparity metrics above are worrisome! We might need to retrain the model, possibly with better feature engineering. That's an exercise for a later time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**V - Conforming Model Code to MOC Requirements**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conformace is best-demonstrated through and example. Let's look at the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import copy\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, f1_score, confusion_matrix\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "from scipy.stats import epps_singleton_2samp, gaussian_kde, ks_2samp\n",
    "\n",
    "# import shap\n",
    "\n",
    "\n",
    "# modelop.init\n",
    "def begin():\n",
    "    \n",
    "    global logreg_classifier\n",
    "    global predictive_features\n",
    "    \n",
    "    # load pickled logistic regression model\n",
    "    logreg_classifier = pickle.load(open(\"logreg_classifier.pickle\", \"rb\"))\n",
    "    \n",
    "    # load pickled predictive feature list\n",
    "    predictive_features = pickle.load(open('predictive_features.pickle', 'rb'))\n",
    "    \n",
    "    \n",
    "def preprocess(data):\n",
    "    # There are only two unique values in data.number_people_liable.\n",
    "    # Treat it as a categorical feature\n",
    "    data['number_people_liable'] = data['number_people_liable'].astype('object')\n",
    "    return data\n",
    "\n",
    "# modelop.score\n",
    "def action(data):\n",
    "    \n",
    "    # Turn data into DataFrame\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    # preprocess data - in this case, only converting one column\n",
    "    # from numerical to categorical\n",
    "    data = preprocess(data)\n",
    "    \n",
    "    # generate predictions\n",
    "    data[\"predicted_score\"] = logreg_classifier.predict(data[predictive_features])\n",
    "    \n",
    "    # MOC expects the action function to be a *yield* function\n",
    "    return data.to_dict(orient=\"records\")\n",
    "    # yield data.to_dict(orient=\"records\")  \n",
    "    \n",
    "# modelop.metrics\n",
    "def metrics(data1, data2 = None):\n",
    "    # dictionary to hold final metrics\n",
    "    metrics = {}\n",
    "    \n",
    "    # convert data into DataFrame\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    # preprocess data - in this case, only converting one column\n",
    "    # from numerical to categorical\n",
    "    data = preprocess(data)\n",
    "    \n",
    "    # generate predicted probabilities\n",
    "    data['predicted_probabilities'] = [y for x, y in logreg_classifier.predict_proba(df[predictive_features])]\n",
    "    \n",
    "    # calculate metrics\n",
    "    f1 = f1_score(data['label_value'], data['score'])\n",
    "    cm = confusion_matrix(data['label_value'], data['score'])\n",
    "    labels = ['label_1', 'label_2']\n",
    "    cm = matrix_to_dicts(cm, labels)\n",
    "    fpr, tpr, thres = roc_curve(data['label_value'], data['predicted_probabilities'])\n",
    "    auc_val = roc_auc_score(data['label_value'], data['predicted_probabilities'])\n",
    "    rc = [{'fpr': x[0], 'tpr': x[1]} for x in list(zip(fpr, tpr))]\n",
    "    metrics['f1_score'] = f1\n",
    "    metrics['confusion_matrix'] = cm\n",
    "    metrics['auc'] = auc_val\n",
    "    metrics['ROC'] = rc\n",
    "    metrics['bias'] = get_bias_metrics(data)\n",
    "#     metrics['drift_metrics'] = get_drift_metrics(data)\n",
    "#     metrics['shap'] = get_shape_values(data)\n",
    "    \n",
    "    # MOC expects the action function to be a *yield* function\n",
    "    # yield metrics\n",
    "    return metrics\n",
    "    \n",
    "    \n",
    "def get_bias_metrics(data):\n",
    "    # To measure Bias towards gender, filter DataFrame\n",
    "    # to \"score\", \"label_value\" (ground truth), and\n",
    "    # \"gender\" (protected attribute)\n",
    "    data_scored = data[[\"score\", \"label_value\", \"gender\"]]\n",
    "\n",
    "    # Process DataFrame\n",
    "    data_scored_processed, _ = preprocess_input_df(data_scored)\n",
    "\n",
    "    # Group Metrics\n",
    "    g = Group()\n",
    "    xtab, _ = g.get_crosstabs(data_scored_processed)\n",
    "\n",
    "    # Absolute metrics, such as 'tpr', 'tnr','precision', etc.\n",
    "    absolute_metrics = g.list_absolute_metrics(xtab)\n",
    "\n",
    "    # DataFrame of calculated absolute metrics for each sample population group\n",
    "    absolute_metrics_df = xtab[\n",
    "        ['attribute_name', 'attribute_value'] + absolute_metrics].round(2)\n",
    "\n",
    "    # For example:\n",
    "    \"\"\"\n",
    "        attribute_name  attribute_value     tpr     tnr  ... precision\n",
    "    0   gender          female              0.60    0.88 ... 0.75\n",
    "    1   gender          male                0.49    0.90 ... 0.64\n",
    "    \"\"\"\n",
    "\n",
    "    # Bias Metrics\n",
    "    b = Bias()\n",
    "\n",
    "    # Disparities calculated in relation gender for \"male\" and \"female\"\n",
    "    bias_df = b.get_disparity_predefined_groups(\n",
    "        xtab,\n",
    "        original_df=data_scored_processed,\n",
    "        ref_groups_dict={'gender': 'male'},\n",
    "        alpha=0.05, mask_significance=True\n",
    "    )\n",
    "\n",
    "    # Disparity metrics added to bias DataFrame\n",
    "    calculated_disparities = b.list_disparities(bias_df)\n",
    "\n",
    "    disparity_metrics_df = bias_df[\n",
    "        ['attribute_name', 'attribute_value'] + calculated_disparities]\n",
    "\n",
    "    # For example:\n",
    "    \"\"\"\n",
    "        attribute_name\tattribute_value    ppr_disparity   precision_disparity\n",
    "    0   gender          female             0.714286        1.41791\n",
    "    1   gender          male               1.000000        1.000000\n",
    "    \"\"\"\n",
    "\n",
    "    output_metrics_df = disparity_metrics_df # or absolute_metrics_df\n",
    "\n",
    "    # Output a JSON object of calculated metrics\n",
    "    \n",
    "    return output_metrics_df.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "def matrix_to_dicts(matrix, labels):\n",
    "    cm = []\n",
    "    for idx, label in enumerate(labels):\n",
    "        cm.append(dict(zip(labels, matrix[idx, :].tolist())))\n",
    "    return cm\n",
    "\n",
    "\n",
    "def get_drift_metrics():\n",
    "\n",
    "def calculate_drift():\n",
    "\n",
    "def calculate_concept_drift():\n",
    "\n",
    "def ks_metric(df1, df2, numerical_columns):\n",
    "    ks_tests = [ks_2samp(data1=df1.loc[:,col], data2=df2.loc[:,col]) for col in numerical_columns]\n",
    "    p_values = [x[1] for x in ks_tests]\n",
    "    list_of_pval = [f\"{col}_p-value\" for col in numerical_columns]\n",
    "    ks_pvalues = dict(zip(list_of_pval, p_values))\n",
    "    return ks_pvalues\n",
    "\n",
    "def es_metric(df1, df2, numerical_columns):\n",
    "    es_tests = []\n",
    "    for col in numerical_columns:\n",
    "        try:\n",
    "            es_test = epps_singleton_2samp(x=df1.loc[:,col], y=df2.loc[:,col])\n",
    "        except np.linalg.LinAlgError:\n",
    "            es_test = [None, None]\n",
    "        es_tests.append(es_test)\n",
    "    p_values = [x[1] for x in es_tests]\n",
    "    list_of_pval = [f\"{col}_p-value\" for col in numerical_columns]\n",
    "    es_pvalues = dict(zip(list_of_pval, p_values))\n",
    "    return es_pvalues\n",
    "\n",
    "def js_metric(df1, df2, numerical_columns, categorical_columns):\n",
    "    res = {}\n",
    "    STEPS = 100\n",
    "    for col in categorical_columns:\n",
    "        col_baseline = df1[col].to_frame()\n",
    "        col_sample = df2[col].to_frame()\n",
    "        col_baseline['source'] = 'baseline'\n",
    "        col_sample['source'] = 'sample'\n",
    "        \n",
    "        col_ = pd.concat([col_baseline, col_sample], ignore_index=True)\n",
    "        \n",
    "        arr = (\n",
    "            col_.groupby([col, 'source'])\n",
    "            .size()\n",
    "            .to_frame()\n",
    "            .reset_index()\n",
    "            .pivot(index=col, columns='source')\n",
    "            .droplevel(0, axis=1)\n",
    "        )\n",
    "        arr_ = arr.div(arr.sum(axis=0), axis=1)\n",
    "        arr_.fillna(0, inplace=True)\n",
    "        js_distance = jensenshannon(\n",
    "            arr_['baseline'].to_numpy(), arr_['sample'].to_numpy()\n",
    "        )\n",
    "        res.update({col: js_distance})\n",
    "    \n",
    "    for col in numerical_columns:\n",
    "        # fit guassian_kde\n",
    "        col_baseline = df1[col]\n",
    "        col_sample = df2[col]\n",
    "        kde_baseline = gaussian_kde(col_baseline)\n",
    "        kde_sample = gaussian_kde(col_sample)\n",
    "        \n",
    "        # get range of values\n",
    "        min_ = min(col_baseline.min(), col_sample.min())\n",
    "        max_ = max(col_baseline.max(), col_sample.max())\n",
    "        range_ = numpy.linspace(start=min_, stop=max_, num=STEPS)\n",
    "        \n",
    "        # sample range from KDE\n",
    "        arr_baseline_ =_ kde_baseline(range_)\n",
    "        arr_sample_ = kde_sample(range_)\n",
    "        \n",
    "        arr_baseline = arr_baseline_ / numpy.sum(arr_baseline_)\n",
    "        arr_sample = arr_sample_ / numpy.sum(arr_sample_)\n",
    "        \n",
    "        # calculate js distance\n",
    "        js_distance = jensenshannon(arr_baseline, arr_sample)\n",
    "        \n",
    "        res.update({col: js_distance})\n",
    "        \n",
    "    list_output = sorted(res.items() key=lambda x: x[1],reverse=True)\n",
    "    dict_output = dict(list_output)\n",
    "    return dict_output\n",
    "        \n",
    "# def get_shap_values(data):\n",
    "#     shap_values = explainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four main sections that are standard to almost any model in MOC:\n",
    "1. Library imports\n",
    "2. `init` function\n",
    "3. `score` function\n",
    "4. `metrics` function\n",
    "\n",
    "**Library** imports are always at the top. We don't need to include all libraries that we used for training and model evaluation. We just need the libraries for processing and scoring.\n",
    "\n",
    "The **`init`** function runs once per deployment, and is used to load and persist into memory any variable that needs to be accessed at scoring time. For example, the init function is where we load the saved model binary. We make the variable global so it can be accessed from the scoring function.\n",
    "\n",
    "The **`score`** function is the function that runs anytime we make a scoring (prediction) request. This is where we put our prediction code. We have to remember to include any steps that were not captured by the pipeline, such as feature engineering or re-encoding.\n",
    "\n",
    "The **`metrics`** functions is where model evaluation is carried out. In our example, this is the place where we replicate the calculations of Group and/or Bias metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test our source code to see if we missed anything. We will load input data and scored input data to test both the scoring and metrics functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = pd.read_json('df_baseline.json', lines=True, orient='records')\n",
    "metrics_sample = pd.read_json('df_baseline_scored.json', lines=True, orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that the **`init`** function can load the trained model binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "begin()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No errors from the **`init`** function. Let us now call the **`score`** function on input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = action(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>duration_months</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>present_residence_since</th>\n",
       "      <th>age_years</th>\n",
       "      <th>number_existing_credits</th>\n",
       "      <th>checking_status</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>installment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>job</th>\n",
       "      <th>number_people_liable</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>687</td>\n",
       "      <td>36</td>\n",
       "      <td>2862</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>A12</td>\n",
       "      <td>A33</td>\n",
       "      <td>A40</td>\n",
       "      <td>...</td>\n",
       "      <td>A124</td>\n",
       "      <td>A143</td>\n",
       "      <td>A153</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>24</td>\n",
       "      <td>3123</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>A11</td>\n",
       "      <td>A32</td>\n",
       "      <td>A40</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332</td>\n",
       "      <td>60</td>\n",
       "      <td>7408</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>A12</td>\n",
       "      <td>A32</td>\n",
       "      <td>A40</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>A143</td>\n",
       "      <td>A152</td>\n",
       "      <td>A174</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>979</td>\n",
       "      <td>15</td>\n",
       "      <td>1264</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>A12</td>\n",
       "      <td>A31</td>\n",
       "      <td>A40</td>\n",
       "      <td>...</td>\n",
       "      <td>A122</td>\n",
       "      <td>A143</td>\n",
       "      <td>A151</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A191</td>\n",
       "      <td>A201</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>817</td>\n",
       "      <td>6</td>\n",
       "      <td>1554</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>A14</td>\n",
       "      <td>A34</td>\n",
       "      <td>A43</td>\n",
       "      <td>...</td>\n",
       "      <td>A123</td>\n",
       "      <td>A143</td>\n",
       "      <td>A151</td>\n",
       "      <td>A173</td>\n",
       "      <td>1</td>\n",
       "      <td>A192</td>\n",
       "      <td>A201</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  duration_months  credit_amount  installment_rate  \\\n",
       "0  687               36           2862                 4   \n",
       "1  500               24           3123                 4   \n",
       "2  332               60           7408                 4   \n",
       "3  979               15           1264                 2   \n",
       "4  817                6           1554                 1   \n",
       "\n",
       "   present_residence_since  age_years  number_existing_credits  \\\n",
       "0                        3         30                        1   \n",
       "1                        1         27                        1   \n",
       "2                        2         24                        1   \n",
       "3                        2         25                        1   \n",
       "4                        2         24                        2   \n",
       "\n",
       "  checking_status credit_history purpose  ... property installment_plans  \\\n",
       "0             A12            A33     A40  ...     A124              A143   \n",
       "1             A11            A32     A40  ...     A122              A143   \n",
       "2             A12            A32     A40  ...     A122              A143   \n",
       "3             A12            A31     A40  ...     A122              A143   \n",
       "4             A14            A34     A43  ...     A123              A143   \n",
       "\n",
       "  housing   job number_people_liable telephone foreign_worker  gender label  \\\n",
       "0    A153  A173                    1      A191           A201    male     0   \n",
       "1    A152  A173                    1      A191           A201  female     1   \n",
       "2    A152  A174                    1      A191           A201  female     1   \n",
       "3    A151  A173                    1      A191           A201    male     1   \n",
       "4    A151  A173                    1      A192           A201  female     0   \n",
       "\n",
       "  predicted_score  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(scores).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have scores! Last but not least, let's call the **`metrics`** function on scored data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/royk/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "metrics_output = metrics(metrics_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'f1_score': 0.6296296296296297,\n",
       " 'confusion_matrix': [{'label_1': 393, 'label_2': 165},\n",
       "  {'label_1': 55, 'label_2': 187}],\n",
       " 'auc': 0.8116650374714891,\n",
       " 'ROC': [{'fpr': 0.0, 'tpr': 0.0},\n",
       "  {'fpr': 0.0, 'tpr': 0.004132231404958678},\n",
       "  {'fpr': 0.0017921146953405018, 'tpr': 0.004132231404958678},\n",
       "  {'fpr': 0.0017921146953405018, 'tpr': 0.012396694214876033},\n",
       "  {'fpr': 0.0035842293906810036, 'tpr': 0.012396694214876033},\n",
       "  {'fpr': 0.0035842293906810036, 'tpr': 0.05785123966942149},\n",
       "  {'fpr': 0.005376344086021506, 'tpr': 0.05785123966942149},\n",
       "  {'fpr': 0.005376344086021506, 'tpr': 0.07024793388429752},\n",
       "  {'fpr': 0.007168458781362007, 'tpr': 0.07024793388429752},\n",
       "  {'fpr': 0.007168458781362007, 'tpr': 0.09090909090909091},\n",
       "  {'fpr': 0.012544802867383513, 'tpr': 0.09090909090909091},\n",
       "  {'fpr': 0.012544802867383513, 'tpr': 0.1115702479338843},\n",
       "  {'fpr': 0.014336917562724014, 'tpr': 0.1115702479338843},\n",
       "  {'fpr': 0.014336917562724014, 'tpr': 0.12396694214876033},\n",
       "  {'fpr': 0.016129032258064516, 'tpr': 0.12396694214876033},\n",
       "  {'fpr': 0.016129032258064516, 'tpr': 0.13636363636363635},\n",
       "  {'fpr': 0.017921146953405017, 'tpr': 0.13636363636363635},\n",
       "  {'fpr': 0.017921146953405017, 'tpr': 0.14049586776859505},\n",
       "  {'fpr': 0.021505376344086023, 'tpr': 0.14049586776859505},\n",
       "  {'fpr': 0.021505376344086023, 'tpr': 0.1487603305785124},\n",
       "  {'fpr': 0.023297491039426525, 'tpr': 0.1487603305785124},\n",
       "  {'fpr': 0.023297491039426525, 'tpr': 0.18181818181818182},\n",
       "  {'fpr': 0.025089605734767026, 'tpr': 0.18181818181818182},\n",
       "  {'fpr': 0.025089605734767026, 'tpr': 0.19008264462809918},\n",
       "  {'fpr': 0.026881720430107527, 'tpr': 0.19008264462809918},\n",
       "  {'fpr': 0.026881720430107527, 'tpr': 0.21487603305785125},\n",
       "  {'fpr': 0.03046594982078853, 'tpr': 0.21487603305785125},\n",
       "  {'fpr': 0.03046594982078853, 'tpr': 0.2231404958677686},\n",
       "  {'fpr': 0.035842293906810034, 'tpr': 0.2231404958677686},\n",
       "  {'fpr': 0.035842293906810034, 'tpr': 0.23553719008264462},\n",
       "  {'fpr': 0.03763440860215054, 'tpr': 0.23553719008264462},\n",
       "  {'fpr': 0.03763440860215054, 'tpr': 0.24380165289256198},\n",
       "  {'fpr': 0.03942652329749104, 'tpr': 0.24380165289256198},\n",
       "  {'fpr': 0.03942652329749104, 'tpr': 0.25206611570247933},\n",
       "  {'fpr': 0.04121863799283154, 'tpr': 0.25206611570247933},\n",
       "  {'fpr': 0.04121863799283154, 'tpr': 0.2603305785123967},\n",
       "  {'fpr': 0.043010752688172046, 'tpr': 0.2603305785123967},\n",
       "  {'fpr': 0.043010752688172046, 'tpr': 0.26859504132231404},\n",
       "  {'fpr': 0.04659498207885305, 'tpr': 0.26859504132231404},\n",
       "  {'fpr': 0.04659498207885305, 'tpr': 0.2768595041322314},\n",
       "  {'fpr': 0.04838709677419355, 'tpr': 0.2768595041322314},\n",
       "  {'fpr': 0.04838709677419355, 'tpr': 0.2892561983471074},\n",
       "  {'fpr': 0.05017921146953405, 'tpr': 0.2892561983471074},\n",
       "  {'fpr': 0.05017921146953405, 'tpr': 0.3140495867768595},\n",
       "  {'fpr': 0.05555555555555555, 'tpr': 0.3140495867768595},\n",
       "  {'fpr': 0.05555555555555555, 'tpr': 0.3305785123966942},\n",
       "  {'fpr': 0.05913978494623656, 'tpr': 0.3305785123966942},\n",
       "  {'fpr': 0.05913978494623656, 'tpr': 0.3347107438016529},\n",
       "  {'fpr': 0.06272401433691756, 'tpr': 0.3347107438016529},\n",
       "  {'fpr': 0.06272401433691756, 'tpr': 0.359504132231405},\n",
       "  {'fpr': 0.07347670250896057, 'tpr': 0.359504132231405},\n",
       "  {'fpr': 0.07347670250896057, 'tpr': 0.36363636363636365},\n",
       "  {'fpr': 0.07706093189964158, 'tpr': 0.36363636363636365},\n",
       "  {'fpr': 0.07706093189964158, 'tpr': 0.3677685950413223},\n",
       "  {'fpr': 0.07885304659498207, 'tpr': 0.3677685950413223},\n",
       "  {'fpr': 0.07885304659498207, 'tpr': 0.371900826446281},\n",
       "  {'fpr': 0.08243727598566308, 'tpr': 0.371900826446281},\n",
       "  {'fpr': 0.08243727598566308, 'tpr': 0.3760330578512397},\n",
       "  {'fpr': 0.08422939068100359, 'tpr': 0.3760330578512397},\n",
       "  {'fpr': 0.08422939068100359, 'tpr': 0.38016528925619836},\n",
       "  {'fpr': 0.08602150537634409, 'tpr': 0.38016528925619836},\n",
       "  {'fpr': 0.08602150537634409, 'tpr': 0.39669421487603307},\n",
       "  {'fpr': 0.08960573476702509, 'tpr': 0.39669421487603307},\n",
       "  {'fpr': 0.08960573476702509, 'tpr': 0.4090909090909091},\n",
       "  {'fpr': 0.0913978494623656, 'tpr': 0.4090909090909091},\n",
       "  {'fpr': 0.0913978494623656, 'tpr': 0.4132231404958678},\n",
       "  {'fpr': 0.0931899641577061, 'tpr': 0.4132231404958678},\n",
       "  {'fpr': 0.0931899641577061, 'tpr': 0.4214876033057851},\n",
       "  {'fpr': 0.09498207885304659, 'tpr': 0.4214876033057851},\n",
       "  {'fpr': 0.09498207885304659, 'tpr': 0.4380165289256198},\n",
       "  {'fpr': 0.0985663082437276, 'tpr': 0.4380165289256198},\n",
       "  {'fpr': 0.0985663082437276, 'tpr': 0.4628099173553719},\n",
       "  {'fpr': 0.10215053763440861, 'tpr': 0.4628099173553719},\n",
       "  {'fpr': 0.10215053763440861, 'tpr': 0.4669421487603306},\n",
       "  {'fpr': 0.1057347670250896, 'tpr': 0.4669421487603306},\n",
       "  {'fpr': 0.1057347670250896, 'tpr': 0.4793388429752066},\n",
       "  {'fpr': 0.11290322580645161, 'tpr': 0.4793388429752066},\n",
       "  {'fpr': 0.11290322580645161, 'tpr': 0.49586776859504134},\n",
       "  {'fpr': 0.11827956989247312, 'tpr': 0.49586776859504134},\n",
       "  {'fpr': 0.11827956989247312, 'tpr': 0.5},\n",
       "  {'fpr': 0.12007168458781362, 'tpr': 0.5},\n",
       "  {'fpr': 0.12007168458781362, 'tpr': 0.5041322314049587},\n",
       "  {'fpr': 0.12365591397849462, 'tpr': 0.5041322314049587},\n",
       "  {'fpr': 0.12365591397849462, 'tpr': 0.512396694214876},\n",
       "  {'fpr': 0.12724014336917563, 'tpr': 0.512396694214876},\n",
       "  {'fpr': 0.12724014336917563, 'tpr': 0.5165289256198347},\n",
       "  {'fpr': 0.12903225806451613, 'tpr': 0.5165289256198347},\n",
       "  {'fpr': 0.12903225806451613, 'tpr': 0.5206611570247934},\n",
       "  {'fpr': 0.13082437275985664, 'tpr': 0.5206611570247934},\n",
       "  {'fpr': 0.13082437275985664, 'tpr': 0.5413223140495868},\n",
       "  {'fpr': 0.13620071684587814, 'tpr': 0.5413223140495868},\n",
       "  {'fpr': 0.13620071684587814, 'tpr': 0.5454545454545454},\n",
       "  {'fpr': 0.14336917562724014, 'tpr': 0.5454545454545454},\n",
       "  {'fpr': 0.14336917562724014, 'tpr': 0.5495867768595041},\n",
       "  {'fpr': 0.14874551971326164, 'tpr': 0.5495867768595041},\n",
       "  {'fpr': 0.14874551971326164, 'tpr': 0.5537190082644629},\n",
       "  {'fpr': 0.15053763440860216, 'tpr': 0.5537190082644629},\n",
       "  {'fpr': 0.15053763440860216, 'tpr': 0.5619834710743802},\n",
       "  {'fpr': 0.15412186379928317, 'tpr': 0.5619834710743802},\n",
       "  {'fpr': 0.15412186379928317, 'tpr': 0.5867768595041323},\n",
       "  {'fpr': 0.15770609318996415, 'tpr': 0.5867768595041323},\n",
       "  {'fpr': 0.15770609318996415, 'tpr': 0.5909090909090909},\n",
       "  {'fpr': 0.15949820788530467, 'tpr': 0.5909090909090909},\n",
       "  {'fpr': 0.15949820788530467, 'tpr': 0.6033057851239669},\n",
       "  {'fpr': 0.16487455197132617, 'tpr': 0.6033057851239669},\n",
       "  {'fpr': 0.16487455197132617, 'tpr': 0.6074380165289256},\n",
       "  {'fpr': 0.16845878136200718, 'tpr': 0.6074380165289256},\n",
       "  {'fpr': 0.16845878136200718, 'tpr': 0.6115702479338843},\n",
       "  {'fpr': 0.17204301075268819, 'tpr': 0.6115702479338843},\n",
       "  {'fpr': 0.17204301075268819, 'tpr': 0.6198347107438017},\n",
       "  {'fpr': 0.17383512544802868, 'tpr': 0.6198347107438017},\n",
       "  {'fpr': 0.17383512544802868, 'tpr': 0.6239669421487604},\n",
       "  {'fpr': 0.17562724014336917, 'tpr': 0.6239669421487604},\n",
       "  {'fpr': 0.17562724014336917, 'tpr': 0.628099173553719},\n",
       "  {'fpr': 0.1774193548387097, 'tpr': 0.628099173553719},\n",
       "  {'fpr': 0.1774193548387097, 'tpr': 0.6363636363636364},\n",
       "  {'fpr': 0.1863799283154122, 'tpr': 0.6363636363636364},\n",
       "  {'fpr': 0.18996415770609318, 'tpr': 0.6363636363636364},\n",
       "  {'fpr': 0.1917562724014337, 'tpr': 0.6363636363636364},\n",
       "  {'fpr': 0.1917562724014337, 'tpr': 0.640495867768595},\n",
       "  {'fpr': 0.1935483870967742, 'tpr': 0.640495867768595},\n",
       "  {'fpr': 0.1935483870967742, 'tpr': 0.6487603305785123},\n",
       "  {'fpr': 0.1971326164874552, 'tpr': 0.6487603305785123},\n",
       "  {'fpr': 0.1971326164874552, 'tpr': 0.6652892561983471},\n",
       "  {'fpr': 0.1989247311827957, 'tpr': 0.6652892561983471},\n",
       "  {'fpr': 0.1989247311827957, 'tpr': 0.6735537190082644},\n",
       "  {'fpr': 0.21505376344086022, 'tpr': 0.6735537190082644},\n",
       "  {'fpr': 0.21505376344086022, 'tpr': 0.6776859504132231},\n",
       "  {'fpr': 0.2168458781362007, 'tpr': 0.6776859504132231},\n",
       "  {'fpr': 0.2168458781362007, 'tpr': 0.6818181818181818},\n",
       "  {'fpr': 0.22043010752688172, 'tpr': 0.6818181818181818},\n",
       "  {'fpr': 0.22043010752688172, 'tpr': 0.6859504132231405},\n",
       "  {'fpr': 0.2222222222222222, 'tpr': 0.6859504132231405},\n",
       "  {'fpr': 0.2222222222222222, 'tpr': 0.6942148760330579},\n",
       "  {'fpr': 0.22580645161290322, 'tpr': 0.6942148760330579},\n",
       "  {'fpr': 0.22580645161290322, 'tpr': 0.6983471074380165},\n",
       "  {'fpr': 0.23655913978494625, 'tpr': 0.6983471074380165},\n",
       "  {'fpr': 0.23655913978494625, 'tpr': 0.7024793388429752},\n",
       "  {'fpr': 0.24551971326164876, 'tpr': 0.7024793388429752},\n",
       "  {'fpr': 0.24551971326164876, 'tpr': 0.7066115702479339},\n",
       "  {'fpr': 0.25448028673835127, 'tpr': 0.7066115702479339},\n",
       "  {'fpr': 0.25448028673835127, 'tpr': 0.7148760330578512},\n",
       "  {'fpr': 0.25627240143369173, 'tpr': 0.7148760330578512},\n",
       "  {'fpr': 0.25627240143369173, 'tpr': 0.7231404958677686},\n",
       "  {'fpr': 0.2616487455197133, 'tpr': 0.7231404958677686},\n",
       "  {'fpr': 0.2616487455197133, 'tpr': 0.731404958677686},\n",
       "  {'fpr': 0.2724014336917563, 'tpr': 0.731404958677686},\n",
       "  {'fpr': 0.2724014336917563, 'tpr': 0.7355371900826446},\n",
       "  {'fpr': 0.27419354838709675, 'tpr': 0.7355371900826446},\n",
       "  {'fpr': 0.27419354838709675, 'tpr': 0.743801652892562},\n",
       "  {'fpr': 0.27598566308243727, 'tpr': 0.743801652892562},\n",
       "  {'fpr': 0.27598566308243727, 'tpr': 0.756198347107438},\n",
       "  {'fpr': 0.27956989247311825, 'tpr': 0.756198347107438},\n",
       "  {'fpr': 0.27956989247311825, 'tpr': 0.7603305785123967},\n",
       "  {'fpr': 0.2903225806451613, 'tpr': 0.7603305785123967},\n",
       "  {'fpr': 0.2903225806451613, 'tpr': 0.768595041322314},\n",
       "  {'fpr': 0.2939068100358423, 'tpr': 0.768595041322314},\n",
       "  {'fpr': 0.2939068100358423, 'tpr': 0.7727272727272727},\n",
       "  {'fpr': 0.2974910394265233, 'tpr': 0.7727272727272727},\n",
       "  {'fpr': 0.2974910394265233, 'tpr': 0.7768595041322314},\n",
       "  {'fpr': 0.2992831541218638, 'tpr': 0.7768595041322314},\n",
       "  {'fpr': 0.2992831541218638, 'tpr': 0.7851239669421488},\n",
       "  {'fpr': 0.3100358422939068, 'tpr': 0.7851239669421488},\n",
       "  {'fpr': 0.3100358422939068, 'tpr': 0.7892561983471075},\n",
       "  {'fpr': 0.32974910394265233, 'tpr': 0.7892561983471075},\n",
       "  {'fpr': 0.32974910394265233, 'tpr': 0.7933884297520661},\n",
       "  {'fpr': 0.33512544802867383, 'tpr': 0.7933884297520661},\n",
       "  {'fpr': 0.33512544802867383, 'tpr': 0.8016528925619835},\n",
       "  {'fpr': 0.33691756272401435, 'tpr': 0.8016528925619835},\n",
       "  {'fpr': 0.33691756272401435, 'tpr': 0.8057851239669421},\n",
       "  {'fpr': 0.34767025089605735, 'tpr': 0.8057851239669421},\n",
       "  {'fpr': 0.34767025089605735, 'tpr': 0.8099173553719008},\n",
       "  {'fpr': 0.3602150537634409, 'tpr': 0.8099173553719008},\n",
       "  {'fpr': 0.3602150537634409, 'tpr': 0.8140495867768595},\n",
       "  {'fpr': 0.36200716845878134, 'tpr': 0.8140495867768595},\n",
       "  {'fpr': 0.36200716845878134, 'tpr': 0.8181818181818182},\n",
       "  {'fpr': 0.3709677419354839, 'tpr': 0.8181818181818182},\n",
       "  {'fpr': 0.3709677419354839, 'tpr': 0.8223140495867769},\n",
       "  {'fpr': 0.37455197132616486, 'tpr': 0.8223140495867769},\n",
       "  {'fpr': 0.37455197132616486, 'tpr': 0.8264462809917356},\n",
       "  {'fpr': 0.3835125448028674, 'tpr': 0.8264462809917356},\n",
       "  {'fpr': 0.3835125448028674, 'tpr': 0.8305785123966942},\n",
       "  {'fpr': 0.3888888888888889, 'tpr': 0.8305785123966942},\n",
       "  {'fpr': 0.3888888888888889, 'tpr': 0.8347107438016529},\n",
       "  {'fpr': 0.4032258064516129, 'tpr': 0.8347107438016529},\n",
       "  {'fpr': 0.4032258064516129, 'tpr': 0.8388429752066116},\n",
       "  {'fpr': 0.4068100358422939, 'tpr': 0.8388429752066116},\n",
       "  {'fpr': 0.4068100358422939, 'tpr': 0.8429752066115702},\n",
       "  {'fpr': 0.4121863799283154, 'tpr': 0.8429752066115702},\n",
       "  {'fpr': 0.4121863799283154, 'tpr': 0.8471074380165289},\n",
       "  {'fpr': 0.41397849462365593, 'tpr': 0.8471074380165289},\n",
       "  {'fpr': 0.41397849462365593, 'tpr': 0.8553719008264463},\n",
       "  {'fpr': 0.44265232974910396, 'tpr': 0.8553719008264463},\n",
       "  {'fpr': 0.44265232974910396, 'tpr': 0.8636363636363636},\n",
       "  {'fpr': 0.44623655913978494, 'tpr': 0.8636363636363636},\n",
       "  {'fpr': 0.44623655913978494, 'tpr': 0.871900826446281},\n",
       "  {'fpr': 0.45161290322580644, 'tpr': 0.871900826446281},\n",
       "  {'fpr': 0.45161290322580644, 'tpr': 0.8760330578512396},\n",
       "  {'fpr': 0.46774193548387094, 'tpr': 0.8760330578512396},\n",
       "  {'fpr': 0.46774193548387094, 'tpr': 0.8801652892561983},\n",
       "  {'fpr': 0.46953405017921146, 'tpr': 0.8801652892561983},\n",
       "  {'fpr': 0.46953405017921146, 'tpr': 0.8925619834710744},\n",
       "  {'fpr': 0.471326164874552, 'tpr': 0.8925619834710744},\n",
       "  {'fpr': 0.471326164874552, 'tpr': 0.8966942148760331},\n",
       "  {'fpr': 0.482078853046595, 'tpr': 0.8966942148760331},\n",
       "  {'fpr': 0.482078853046595, 'tpr': 0.9008264462809917},\n",
       "  {'fpr': 0.48566308243727596, 'tpr': 0.9008264462809917},\n",
       "  {'fpr': 0.48566308243727596, 'tpr': 0.9090909090909091},\n",
       "  {'fpr': 0.4874551971326165, 'tpr': 0.9090909090909091},\n",
       "  {'fpr': 0.4874551971326165, 'tpr': 0.9132231404958677},\n",
       "  {'fpr': 0.4910394265232975, 'tpr': 0.9132231404958677},\n",
       "  {'fpr': 0.4910394265232975, 'tpr': 0.9214876033057852},\n",
       "  {'fpr': 0.510752688172043, 'tpr': 0.9214876033057852},\n",
       "  {'fpr': 0.510752688172043, 'tpr': 0.9256198347107438},\n",
       "  {'fpr': 0.532258064516129, 'tpr': 0.9256198347107438},\n",
       "  {'fpr': 0.532258064516129, 'tpr': 0.9297520661157025},\n",
       "  {'fpr': 0.5448028673835126, 'tpr': 0.9297520661157025},\n",
       "  {'fpr': 0.5448028673835126, 'tpr': 0.9338842975206612},\n",
       "  {'fpr': 0.5591397849462365, 'tpr': 0.9338842975206612},\n",
       "  {'fpr': 0.5591397849462365, 'tpr': 0.9380165289256198},\n",
       "  {'fpr': 0.5645161290322581, 'tpr': 0.9380165289256198},\n",
       "  {'fpr': 0.5645161290322581, 'tpr': 0.9421487603305785},\n",
       "  {'fpr': 0.5698924731182796, 'tpr': 0.9421487603305785},\n",
       "  {'fpr': 0.5698924731182796, 'tpr': 0.9462809917355371},\n",
       "  {'fpr': 0.5913978494623656, 'tpr': 0.9462809917355371},\n",
       "  {'fpr': 0.5913978494623656, 'tpr': 0.9504132231404959},\n",
       "  {'fpr': 0.5949820788530465, 'tpr': 0.9504132231404959},\n",
       "  {'fpr': 0.5949820788530465, 'tpr': 0.9545454545454546},\n",
       "  {'fpr': 0.5985663082437276, 'tpr': 0.9545454545454546},\n",
       "  {'fpr': 0.5985663082437276, 'tpr': 0.9586776859504132},\n",
       "  {'fpr': 0.6039426523297491, 'tpr': 0.9586776859504132},\n",
       "  {'fpr': 0.6039426523297491, 'tpr': 0.9628099173553719},\n",
       "  {'fpr': 0.6093189964157706, 'tpr': 0.9628099173553719},\n",
       "  {'fpr': 0.6093189964157706, 'tpr': 0.9710743801652892},\n",
       "  {'fpr': 0.6451612903225806, 'tpr': 0.9710743801652892},\n",
       "  {'fpr': 0.6451612903225806, 'tpr': 0.9752066115702479},\n",
       "  {'fpr': 0.6792114695340502, 'tpr': 0.9752066115702479},\n",
       "  {'fpr': 0.6792114695340502, 'tpr': 0.9793388429752066},\n",
       "  {'fpr': 0.7903225806451613, 'tpr': 0.9793388429752066},\n",
       "  {'fpr': 0.7903225806451613, 'tpr': 0.9834710743801653},\n",
       "  {'fpr': 0.8064516129032258, 'tpr': 0.9834710743801653},\n",
       "  {'fpr': 0.8064516129032258, 'tpr': 0.987603305785124},\n",
       "  {'fpr': 0.8405017921146953, 'tpr': 0.987603305785124},\n",
       "  {'fpr': 0.8405017921146953, 'tpr': 0.9917355371900827},\n",
       "  {'fpr': 0.8476702508960573, 'tpr': 0.9917355371900827},\n",
       "  {'fpr': 0.8476702508960573, 'tpr': 0.9958677685950413},\n",
       "  {'fpr': 0.8870967741935484, 'tpr': 0.9958677685950413},\n",
       "  {'fpr': 0.8870967741935484, 'tpr': 1.0},\n",
       "  {'fpr': 1.0, 'tpr': 1.0}],\n",
       " 'bias': [{'attribute_name': 'gender',\n",
       "   'attribute_value': 'female',\n",
       "   'ppr_disparity': 0.5042735042735043,\n",
       "   'pprev_disparity': 1.190763484881132,\n",
       "   'precision_disparity': 1.1072033898305087,\n",
       "   'fdr_disparity': 0.8871543264942017,\n",
       "   'for_disparity': 1.2228070175438595,\n",
       "   'fpr_disparity': 1.1736158578263842,\n",
       "   'fnr_disparity': 0.8414786967418546,\n",
       "   'tpr_disparity': 1.0501984126984127,\n",
       "   'tnr_disparity': 0.9317510076130765,\n",
       "   'npv_disparity': 0.9708045977011494},\n",
       "  {'attribute_name': 'gender',\n",
       "   'attribute_value': 'male',\n",
       "   'ppr_disparity': 1.0,\n",
       "   'pprev_disparity': 1.0,\n",
       "   'precision_disparity': 1.0,\n",
       "   'fdr_disparity': 1.0,\n",
       "   'for_disparity': 1.0,\n",
       "   'fpr_disparity': 1.0,\n",
       "   'fnr_disparity': 1.0,\n",
       "   'tpr_disparity': 1.0,\n",
       "   'tnr_disparity': 1.0,\n",
       "   'npv_disparity': 1.0}]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
